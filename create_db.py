# create_db.py
"""
ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ìƒì„± ìŠ¤í¬ë¦½íŠ¸
ì›ë³¸ ë¬¸ì„œë“¤ì„ ë²¡í„°í™”í•˜ì—¬ FAISS ì¸ë±ìŠ¤ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
"""

import os
import json
import pickle
from llama_index.core import SimpleDirectoryReader
from llama_index.embeddings.huggingface import HuggingFaceEmbedding
import kss
import faiss
import numpy as np

def create_database():
    """ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ìƒì„± ë©”ì¸ í•¨ìˆ˜"""
    
    # data í´ë” ì¡´ì¬ í™•ì¸
    if not os.path.exists("./data"):
        print("âŒ data í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. data í´ë”ë¥¼ ìƒì„±í•˜ê³  ë¬¸ì„œë¥¼ ì¶”ê°€í•´ì£¼ì„¸ìš”.")
        os.makedirs("./data")
        print("âœ… data í´ë”ë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤. ë¶„ì„í•  ë¬¸ì„œë“¤ì„ data í´ë”ì— ë„£ì–´ì£¼ì„¸ìš”.")
        return
    
    # ë¬¸ì„œ íŒŒì¼ í™•ì¸
    files = os.listdir("./data")
    document_files = [f for f in files if f.endswith(('.pdf', '.txt', '.md')) and f != 'README.md']
    if not document_files:
        print("âŒ data í´ë”ì— ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤. PDF, TXT ë“±ì˜ ë¬¸ì„œë¥¼ ì¶”ê°€í•´ì£¼ì„¸ìš”.")
        return
    
    print(f"ğŸ“ ë°œê²¬ëœ ë¬¸ì„œ íŒŒì¼: {document_files}")
    
    try:
        print("1. ì›ë³¸ ë¬¸ì„œ ë¡œë”©ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
        documents = SimpleDirectoryReader("./data").load_data()
        print(f"   âœ… {len(documents)}ê°œì˜ ë¬¸ì„œë¥¼ ë¡œë”©í–ˆìŠµë‹ˆë‹¤.")
        
        print("2. kss ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ í†µí•´ í•œêµ­ì–´ ë¬¸ì¥ì„ ë¶„ë¦¬í•©ë‹ˆë‹¤...")
        texts = []
        metadatas = []
        
        for doc in documents:
            # README.md íŒŒì¼ ì œì™¸
            if doc.metadata.get("file_name", "") == "README.md":
                continue
                
            sentences = kss.split_sentences(doc.text)
            
            for sentence in sentences:
                if sentence.strip() and len(sentence.strip()) > 10:  # ë„ˆë¬´ ì§§ì€ ë¬¸ì¥ ì œì™¸
                    texts.append(sentence.strip())
                    metadatas.append({
                        "source": doc.metadata.get("file_name", "N/A"),
                        "length": len(sentence.strip())
                    })
        
        print(f"   âœ… ì´ {len(texts)}ê°œì˜ ë¬¸ì¥ìœ¼ë¡œ ë¶„ë¦¬í–ˆìŠµë‹ˆë‹¤.")
        
        if not texts:
            print("âŒ ì²˜ë¦¬í•  í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        print("3. ì„ë² ë”© ëª¨ë¸ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤...")
        embedding_model = HuggingFaceEmbedding(model_name="BAAI/bge-m3")
        
        print("4. í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜í•©ë‹ˆë‹¤...")
        print("   (ì´ ê³¼ì •ì€ ë¬¸ì„œ í¬ê¸°ì— ë”°ë¼ ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
        
        embeddings = []
        batch_size = 32
        
        for i in range(0, len(texts), batch_size):
            batch_texts = texts[i:i+batch_size]
            batch_embeddings = embedding_model.get_text_embedding_batch(batch_texts)
            embeddings.extend(batch_embeddings)
            print(f"   ì§„í–‰ë¥ : {min(i+batch_size, len(texts))}/{len(texts)}")
        
        print("5. FAISS ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤...")
        embeddings_array = np.array(embeddings).astype('float32')
        dimension = embeddings_array.shape[1]
        
        # FAISS ì¸ë±ìŠ¤ ìƒì„±
        index = faiss.IndexFlatIP(dimension)  # ë‚´ì  ìœ ì‚¬ë„ ì‚¬ìš©
        index.add(embeddings_array)
        
        print("6. ë°ì´í„°ë² ì´ìŠ¤ íŒŒì¼ì„ ì €ì¥í•©ë‹ˆë‹¤...")
        
        # FAISS ì¸ë±ìŠ¤ ì €ì¥
        faiss.write_index(index, "document_memory.faiss")
        
        # í…ìŠ¤íŠ¸ì™€ ë©”íƒ€ë°ì´í„° ì €ì¥
        with open("document_memory.pkl", "wb") as f:
            pickle.dump({
                "texts": texts,
                "metadatas": metadatas,
                "embedding_model": "BAAI/bge-m3"
            }, f)
        
        print("âœ… ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        print(f"ğŸ“Š ì²˜ë¦¬ëœ ë¬¸ì¥ ìˆ˜: {len(texts)}")
        print(f"ğŸ“Š ë²¡í„° ì°¨ì›: {dimension}")
        
        # ìƒì„±ëœ íŒŒì¼ í¬ê¸° í™•ì¸
        faiss_size = os.path.getsize("document_memory.faiss") / (1024 * 1024)
        pkl_size = os.path.getsize("document_memory.pkl") / (1024 * 1024)
        print(f"ğŸ“Š FAISS ì¸ë±ìŠ¤ í¬ê¸°: {faiss_size:.2f} MB")
        print(f"ğŸ“Š í…ìŠ¤íŠ¸ ë°ì´í„° í¬ê¸°: {pkl_size:.2f} MB")
        
    except Exception as e:
        print(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        print("   - í•„ìš”í•œ íŒ¨í‚¤ì§€ê°€ ëª¨ë‘ ì„¤ì¹˜ë˜ì—ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”")
        print("   - GPU ë©”ëª¨ë¦¬ê°€ ì¶©ë¶„í•œì§€ í™•ì¸í•´ì£¼ì„¸ìš”")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    create_database()